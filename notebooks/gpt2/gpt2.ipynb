{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "YilE_RQKtZHe"
      },
      "outputs": [],
      "source": [
        "# from datasets import load_dataset\n",
        "import json\n",
        "from sklearn.model_selection import train_test_split\n",
        "from huggingface_hub import login\n",
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel, Trainer, TrainingArguments\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x9QGICFktZHg"
      },
      "source": [
        "## Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "KwgfED3PtZHi"
      },
      "outputs": [],
      "source": [
        "def dataset_gen(text_file):\n",
        "    with open(text_file, 'r', encoding='utf-8') as f:\n",
        "        lines = f.readlines()\n",
        "\n",
        "    texts = [line.strip() for line in lines if len(line.strip()) > 0]\n",
        "    train_texts, val_texts = train_test_split(texts, test_size=0.1)\n",
        "    return train_texts, val_texts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "PMlglrWGtZHi"
      },
      "outputs": [],
      "source": [
        "train_texts, val_texts = dataset_gen('../../data/mahabharat.txt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ljrsYwXvtZHj",
        "outputId": "bd739011-37f4-4632-c9a5-2f32f47159cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of training samples: 2327\n",
            "Number of validation samples: 259\n",
            "Example training sample:\n",
            "\"Afflicted by the god of love,\" Kichaka said, \"I will come alone so that your five husbands will not know of our love affair.\"\n"
          ]
        }
      ],
      "source": [
        "print(f\"Number of training samples: {len(train_texts)}\")\n",
        "print(f\"Number of validation samples: {len(val_texts)}\")\n",
        "print(f\"Example training sample:\\n{train_texts[0]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wc78xsKEtZHj"
      },
      "source": [
        "## Fine Tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g3-SAfv0tZHj"
      },
      "source": [
        "### Tokenize Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BAgK1QZDtZHk",
        "outputId": "c4c6e81d-b157-4572-8ce8-5c289f105d6d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "model_name = \"gpt2\"\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
        "tokenizer.pad_token = tokenizer.eos_token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "KdV-We8EtZHk"
      },
      "outputs": [],
      "source": [
        "def tokenize_data(texts):\n",
        "    encodings = tokenizer(texts, padding=\"max_length\", truncation=True, max_length=512, return_tensors=\"pt\")\n",
        "    encodings[\"labels\"] = encodings[\"input_ids\"].clone()\n",
        "    return encodings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Joxxg08MtZHk",
        "outputId": "c8cd82cd-7fb4-414d-9b23-389f45609211"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Example training input dimensions: torch.Size([512])\n",
            "Example word embedding:\n",
            "Text: ['\"Afflicted', 'by', 'the', 'god', 'of']\n",
            "Embedding: tensor([    1, 35191, 17823,   416,   262,  5770,   286])\n"
          ]
        }
      ],
      "source": [
        "train_encodings = tokenize_data(train_texts)\n",
        "val_encodings = tokenize_data(val_texts)\n",
        "\n",
        "sample_length = 5\n",
        "print(f\"Example training input dimensions: {train_encodings['input_ids'][0].shape}\")\n",
        "print(f\"Example word embedding:\\nText: {train_texts[0].split(' ')[:sample_length]}\\nEmbedding: {train_encodings['input_ids'][0][:sample_length+2]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m-qlvi1CtZHl"
      },
      "source": [
        "### Create Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "xFpIVjZ6tZHl"
      },
      "outputs": [],
      "source": [
        "class TextDataset(Dataset):\n",
        "    def __init__(self, encodings):\n",
        "        self.encodings = encodings\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encodings[\"input_ids\"])\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: val[idx].clone().detach() for key, val in self.encodings.items()}\n",
        "        return item"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "j8ceCQ4XtZHl"
      },
      "outputs": [],
      "source": [
        "train_dataset = TextDataset(train_encodings)\n",
        "val_dataset = TextDataset(val_encodings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hmGFSagKtZHl"
      },
      "source": [
        "### Fine tuning the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "IeRO1Os-tZHl"
      },
      "outputs": [],
      "source": [
        "model = GPT2LMHeadModel.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "7ql_PnkntZHl"
      },
      "outputs": [],
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"../../results\",\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        "    warmup_steps=500,\n",
        "    per_device_train_batch_size=4,\n",
        "    per_device_eval_batch_size=4,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "WaWeHMNutZHm"
      },
      "outputs": [],
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "id": "qt2rcuDxtZHm",
        "outputId": "0c23c6d0-03d7-426d-a4aa-e26a6ec6f1c9"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1746' max='1746' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1746/1746 18:55, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>1.117800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.801600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.736000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=1746, training_loss=0.8649477701962746, metrics={'train_runtime': 1136.4326, 'train_samples_per_second': 6.143, 'train_steps_per_second': 1.536, 'total_flos': 1824079675392000.0, 'train_loss': 0.8649477701962746, 'epoch': 3.0})"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZmjEALpgtZHm",
        "outputId": "b009bd4a-da6a-411d-b069-a554271028eb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('./fine-tuned-gpt2/tokenizer_config.json',\n",
              " './fine-tuned-gpt2/special_tokens_map.json',\n",
              " './fine-tuned-gpt2/vocab.json',\n",
              " './fine-tuned-gpt2/merges.txt',\n",
              " './fine-tuned-gpt2/added_tokens.json')"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.save_pretrained(\"../../fine-tuned-gpt2\")\n",
        "tokenizer.save_pretrained(\"../../fine-tuned-gpt2\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jgmeUVX6tZHm"
      },
      "source": [
        "## Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "sdPzpqeRtZHm"
      },
      "outputs": [],
      "source": [
        "model_path = \"../../fine-tuned-gpt2\"\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(model_path)\n",
        "model = GPT2LMHeadModel.from_pretrained(model_path)\n",
        "\n",
        "if tokenizer.pad_token_id is None:\n",
        "    tokenizer.pad_token_id = tokenizer.eos_token_id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "W51t9YlltZHm"
      },
      "outputs": [],
      "source": [
        "def generate_story(prompt):\n",
        "    input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
        "    attention_mask = input_ids.ne(tokenizer.pad_token_id)\n",
        "    output = model.generate(input_ids, attention_mask=attention_mask, max_length=250, num_return_sequences=1, no_repeat_ngram_size=2, do_sample=True, top_k=50, top_p=0.95)\n",
        "    return tokenizer.decode(output[0], skip_special_tokens=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bzbTGl6stZHn",
        "outputId": "ed1e20d9-3e1a-4a82-a3d4-d635bd5ba46e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        }
      ],
      "source": [
        "story = \"Once upon a time in the Mahabharat, Arjuna\"\n",
        "gen_story = generate_story(story)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vJOkPCcI2wfc",
        "outputId": "77d91f3a-1f22-484b-bcbd-fe3ccb29e8b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Once upon a time in the Mahabharat, Arjuna Once upon a time in the Mahabharat, Arjuna attacked Lord Krishna, the son of Panchala. After killing five hundred kshatriya warriors, they all came out of the battlefield with broken limbs and their heads tied by ropes. Lord Shiva addressed them, \"O pious son, please give me protection from these fierce Bhishma's arrows. I have been slain by the sons of Pritha's son in battle. O son, please accept the blessings of victory and slay my sons, O Krishna!\" The warrior who had been defeated, however, then began to fight with Arjun and killed his two horses and charioteer.\n"
          ]
        }
      ],
      "source": [
        "print(story, gen_story)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
